import chromadb
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# ì „ì—­ ë³€ìˆ˜ë¡œ vectorstoreì™€ embeddings ì €ì¥
_vectorstore = None
_embeddings = None

def get_embeddings():
    global _embeddings
    
    # ì´ë¯¸ ë¡œë“œëœ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
    if _embeddings is not None:
        print("[Debug] ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ ì¬ì‚¬ìš©")
        return _embeddings
    
    model_name = "jhgan/ko-sroberta-multitask"
    model_kwargs = {'device': 'cpu'} 
    encode_kwargs = {'normalize_embeddings': True}
    
    print(f"[Debug] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {model_name}")
    
    _embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs=model_kwargs,
        encode_kwargs=encode_kwargs
    )
    
    return _embeddings

def create_vector_db(full_text):
    global _vectorstore
    
    print("\n[VectorDB] í…ìŠ¤íŠ¸ ì²­í‚¹ ì‹œì‘...")

    embeddings = get_embeddings()

    CHUNK_SIZE = 500
    CHUNK_OVERLAP = 100

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", " ", ""],
        length_function=len
    )

    if len(full_text) < 50:
        print("[Warning] í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
        docs = []
    else:
        texts = text_splitter.split_text(full_text)
        docs = [Document(page_content=t) for t in texts]
    
    print(f"  - ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}ì")
    print(f"  - Chunk Size: {CHUNK_SIZE}, Overlap: {CHUNK_OVERLAP}")
    print(f"  - ìƒì„±ëœ ì²­í¬ ê°œìˆ˜: {len(docs)}ê°œ")
    
    # ğŸ”¥ í•µì‹¬: ëª…ì‹œì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    print("[VectorDB] EphemeralClient ìƒì„± ì¤‘...")
    client = chromadb.EphemeralClient()
    print("[VectorDB] EphemeralClient ìƒì„± ì™„ë£Œ!")
    
    # ë©”ëª¨ë¦¬ ê¸°ë°˜ ChromaDB ìƒì„±
    print("[VectorDB] Chroma vectorstore ìƒì„± ì¤‘...")
    _vectorstore = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        collection_name="investment_strategies",
        client=client  # ğŸ”¥ ë°˜ë“œì‹œ í•„ìš”!
    )
    
    print(f"[VectorDB] âœ… ë©”ëª¨ë¦¬ ê¸°ë°˜ ì €ì¥ ì™„ë£Œ! (EphemeralClient)")
    return _vectorstore

def search_strategy(query, k=3):
    global _vectorstore
    
    print(f"\n[Search] ê²€ìƒ‰ ì§ˆì˜: '{query}'")
    
    if _vectorstore is None:
        raise ValueError("[Error] VectorStoreê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. create_vector_db()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ê²€ìƒ‰
    results = _vectorstore.similarity_search(query, k=k)
    
    print(f"[Search] ê²€ìƒ‰ ê²°ê³¼ {len(results)}ê±´:")
    for i, res in enumerate(results):
        preview = res.page_content[:80].replace('\n', ' ')
        print(f"  [{i+1}] {preview}...")
    
    return results

def reset_db():
    global _vectorstore, _embeddings
    _vectorstore = None
    _embeddings = None
    print("[Info] ë©”ëª¨ë¦¬ DB ë° ì„ë² ë”© ì´ˆê¸°í™” ì™„ë£Œ")